---
layout: post
title: 多模态大模型主流架构介绍 | 苗佳哲
categories: [多模态大模型]
description: 从 LLaVA 到 Qwen3-VL，解构多模态大模型的演进之路
keywords:  
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
topmost: true
---

## 多模态大模型

引言：当 AI 睁开双眼，我们看到了一个怎样的未来？
曾几何时，我们对人工智能的印象还停留在那个聪慧但略显“盲目”的“数字大脑”上——它能写诗、能编程、能回答深奥的哲学问题，但这一切都局限于冰冷的文本世界。然而，就在最近两年，一场深刻的变革正在悄然发生。
您或许已经惊叹于 GPT-5 那般流畅自如的实时图片对话，它能“看到”您房间的布局并给出整理建议；又或者，您可能对 Qwen3-VL 直接“注视”着手机屏幕、精准地点击按钮、操作应用程序的能力感到不可思议。AI 不再仅仅是一个“只会读书”的语言模型，它正在进化成一个能听、会看、可交互的“智能体”，真正地睁开了双眼，开始感知和理解我们所处的这个五彩斑斓的物理世界。这场从“符号”到“感知”的飞跃，背后究竟隐藏着怎样的技术密码？AI 是如何跨越数字与现实的鸿沟，实现从纯文本“思考”到图文视频并茂的“感知与交互”的？
答案，就蕴藏在多模态大模型 (Multimodal Large Models, MLLM) 的架构革命之中。而在 MLLM 这条充满创新与探索的赛道上，涌现出了两条截然不同但都极其成功的技术演进路线。本文将聚焦于这两条路线的杰出代表：以“大道至简”为核心逻辑的 LLaVA 系列，以及奉行“深度融合”设计思想的 Qwen3-VL。在接下来的内容中，我们将一同踏上这场解构之旅。我们首先会搭建起 MLLM 通用的“三位一体”黄金架构蓝图，理解其运作的基础；随后，我们将深入一个所有 MLLM 都必须面对的核心矛盾——如何让模型在不牺牲效率的前提下，看得更“清晰”？ 最终，我们将通过全景式地剖析 LLaVA 与 Qwen3-VL 的架构演进与核心技术，看它们如何分别给出了两条路径迥异却同样精彩的答案。
https://zhuanlan.zhihu.com/p/1963658684765833212